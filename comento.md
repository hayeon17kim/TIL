## 1주차

- 어떻게 클라우드 직무를 시작하게 되었는지?
- 왜 클라우드와 쿠버네티스를 사용하는가?
- 5주간 프로젝트는 어떻게 진행되는가?
  - 1주차 과제 진행
  - 2주차 과제 진행

### 클라우드 운영자가 되려면 어떻게 준비해야 하는가?

- 지식과 경험
  - AWS, GCP, Azure 등을 활용하여 클라우드 이용 경험이 있으면 좋다.
  - OS, 네트워크 등 인프라 지식이 있으면 업무에 많은 도움이 된다.
  - 가상화에 대한 이해가 필요하다. (클라우드가 기본적으로 가상화에서 나왔기 때문이다.)
- 인프라, 온프레미스, 레거시: 모두 같은 것을 의미한다. (물리적인 장비를 다루는 사람) ⇒ 따라서 클라우드 직무와는 다르다.

OpenStack 등을 이ß용하여 자체 개발한 Private 클라우드를 운영할 수도 있고, CSP가 제공하는 Public 클라우드 환경을 운영할 수도 있다.

### 왜 클라우드와 쿠버네티스를 사용하는가?

- 메인프레임
  - 안정성
  - 가격
  - 운영비용
  - 성능
  - 금융권처럼 안정성이 중요한 곳에서 사용 (아직도 사용하는 곳 있음)
  - 크기도 작고 접근성도 쉬웠으면..
- 유닉스
  - 벤더 종속성 → 벤더에 lock in
  - 벤더마다 호환되는 CPU가 따로 존재한다.
  - 벤더마다 호환되는 CPU(OS) ↔ OS 다름
    - 벤더 - 호환되는 OS
    - sun - Solaris
    - IBM - AIX
    - HP - UX
  - 운영 환경이 조금씩 다르기 때문에 함부로 바꾸기가 어렵다. 악조건 속에서도 HP를 사용해야 한다.
  - intel의 CPU 점유율 성장
- 리눅스
  - 벤더 종속 X
  - 벤더에 관계없이 모든 CPU에서 실행 가능한 OS
  - 확장성
  - open source → 공짜
    - 공짜는 공짜지만 AS가 되지 않는다. 그래서 대기업에서 사용하기 힘들다.
  - But 패치 지원 X
  - 일반 기업은 기술 지원 해주는 엔터프라이즈급의 상용 서비스를 사용한다 (Red Hat) (중요한 패치 버전이 있을 때 알아서 교체해준다.)
  - 여기서 CentOS가 있다. RedHat과 똑같다. 대신 RedHat 패치되면 6개월 뒤에 나온다. 실무에서는 반은 RedHat, CentOS.  엔지니어가 조치해준 것과 동일.
  - 서버 증감의 어려움. 공간, 비용, 시간 등 절약 필요
- 클라우드
  - ex) AWS, Azure, GCP
  - 사용한 만큼 비용 지불
  - 서버 증설, 교체, 설정 X
  - 1년, 3년 약정을 통해 비용 절감 가능
  - ex) AWS Saving Plans, Reserved Instance
  - 리테일 회사인데 블랙 프라이데이에 트래픽이 확 몰린다. 그때 증설시킨다. 그러나 그 뒤에는 트래픽이 확 준다. 이미 증설했는데! 이래서 클라우드가 나왔다. 내가 사용자에게 VM을 주면너네는 갖다 쓰기만 해. 그럼 쓴 만큼 돈 내...
  - 맨 처음에는 증감이 많을 것이다.
  - 사용한 만큼 비용 지불하는 것은 온디맨드이다.
  - 그러나 안정적으로 C5 Large 타입을 사용한다면 약정을 통해 사용하면 된다. 이러면 환불하기 어려워 증감이 어렵지만 그래도 이때는
  - AWS Saving Plans, Reserved Plaan

### 왜 쿠버네티스를 사용하는가?

- 물리적인 머신 위에  여러개의 논리적인 서버를 설치해서 CPU와 메모리를 분할해서 쓰는 가상화 기법(Virtual Mache) : 물리 장비에 OS도 따로 있고, VM에 OS도 따로 있다. 무겁기 때문에 부팅 시간이 오래 걸린다.
- 웹 서비스를 하려고 VM을 할당받는다. 그런데 트래픽이 늘면 증설을 해야 한다. VM 자체의 스펙을 높이지 않고 VM을 하나 더 띄워서 병렬 서비스를 한다. (config 설정, 어쩌구 저쩌구 프로세스 띄우고 어플리케이션 띄우고.. )
- 마이크로서비스아키텍처: 자주, 빨리, 배포를 해야 하는 상황.   ⇒ 이럼 가상화면 배포하기 너무 어려워짐
- MSA 유행, 잦은 배포
- Container
  - 기본적으로 호스트 OS의 것을 같이 쓴다.
  - 격리된 고간에서 프로세스를 동작시키는 가상화 기법
  - 확장성 (이 컴퓨터에 띄워도, 응용프로그램 돌아가고 다른 컴퓨터에 띄워도 돌아간다)
  - 도커 파일에 해야 할 cmd 명령어 올리고 붙이고 이걸 싹 도커 파일에 말아서 도커 허브라는 도커 레지스트리에 올린다. 내가 언제나 이 컨테이너를 실행시키고 싶을 때 이 컨테이너를 이미지에 땡ㅋ겨와서 도커 런 어떠죽 하면 아무데서나 띄울 수 있다. 매번 config, 포트 설정 필요 없다.
  - 가벼움 (stop시키면 바로 내려간다.)
  - 자주, 빠르게 배포하는 환경에 적합
  - eX) docker
  - 도커도 한개는 관리하기 쉽지만 100개라면? 호스트 머신이 2개가 있다 .그럼 50개 50개를 관리한다고 하자. 그런데 하나의 컨테이너가 죽었다. 그래서 49개가 된다. 맨날 컴퓨터를 확인하면서 리소스가 부족하네,... CPU가 꽉차있네 하면서 컨테이너를 할당한다면? 이것을 사람이 한다고 하면 너무 힘들다.
  - 자동으로 리소스 있는 곳에 이동하고, 등.ㅠ
- 쿠버네티스
  - 컨테이너 오케스트레이션 툴
  - 컨테이너를 쉽고 빠르게 배포/확장하고 관리를 자동화해주는 오픈소스 플랫폼
  - 도커 컨테이너 관리
  - 우아하게 컨테이너가 업데이트할 수 있도록 해준다.
  - ex) Kubernetes, docker swarm

### 5주간 프로젝트

DevOps

- 클라우드를 구축하는 것
- 클라우드 인벤토리 관리 ⇒ 자산관리 문서 양식 제출: 5주차때 설명해줄 것

AWS란

- Amazone에서 개발한 클라우드 컴퓨팅 플랫폼
- 네트워킹 기반으로 가상 컴퓨터와 스토리지, 네트워크 인프라 등 다양한 서비스를 제공
- 인프라(컴퓨팅, 네트워크, 스토리지 등), 플랫폼(DB, 분석, 배포관리) 등 다양한 서비스 클라우드로 제공 (DB는 접근하지 못해서 플랫폼)

AWS에서 제공하는 서비스

1. 컴퓨팅:  EC2, Lambda 등: EC2(=Virtual Machine ) → 1주차, Lambda(=Serverless 컴퓨팅
2. 네트워킹 - VPC, Route53, Direct Conhnect
3. 스토리지 - S3, EPS
4. 데이터베이스 - RDS, DynamicDB, ElastiCache
5. 관리도구 - CloudWtach, Config, Cloudtrail
6. 보안 - IAM, WAF&Shield, Certificate Manager 등

처음 가입을 하면 root계정이 있다. 이 root로 계속 하는 것은 안좋다. root계정을 처음 회원 가입할 때만 쓰는 것이 좋다. 각각의 리소스마다 접근하는 IAM을 구분. 접근 포인트가 많을 수록 장애가 많이 난다. EC2는

장애 발생 책임 소재를 명확히 하기 위해 1인 1계정.

멘토 계정에는  MFA설정하면 안 된다!

### VPC

- 논리적으로 격리된 공간을 프로비저닝 (= 가상 네트워크 환경)
- 하나의 계정에서 생성하는 리소스들만의 격리된 네트워크 환경 구성 가능
- AWS는 물리적인 호스트 장비가 있고 VM을 할당한다. 논리적으로. 같은 계정에서 만드는 자원들을 어떤 계정 A의 VPC안에서 생성
- 논리적인 독립 네트워크를 구성하는 리소스
- CIDR 범위는 사설 대역으로 설정 (사설망 대역: 10.0.0/8, 172.16.0.0/12, 1)
- 과제에서는 10.0.0/16: 아이피를 갖다 쓸 때 빠리 갖다 쓰라고. 이 리소스들은 이 범위 안에서 아이피를 할당받을 것.
- VPC를 잘게 쪼개서 더 많은 망을 만들어낼 수 있다. 이것이  Subnet이다.

### Subnet

- Multi AZ: 하나 이상의 Availability Zone 에 유사한 리소스를 동시에 배치하는 기능 .AZ는 물리적인 공간으로 분리되어 있기 때문에 이중화 구성하여 하나의 AZ에 장애가 발생하더라도 서비스에 문제 없음 추가비용 X. 추가 비용이 없는 것으로 알고 있음. 동일한 리소스를 각각.
- 인터넷 게이트웨이를 붙이면 public(인바운드, 아웃바운드). 아니면 pirvate
- public vs private
- VPC 에서 생성된 리소스들은 인터넷을 사용할 수 없다. 인터넷 게이트웨이를 붙여준다.
- NAT Gateway: 비용
- NAT Instance: 무료 - Ec2에서 NAT 기능을 사용할 수 있는 ..
- 영역은 도쿄가 아니라 서울로 하면 좋다.

아마존 리눅스 OS를 선택했다. 레드헷 기반이기 때문에 yum을 사용한다. 이런 것을 할 때  outbound 트래픽이 필요하다 . 외부의 것을 땡겨올 수는 있어야 한다. 패키지를 다운받아야 하니까. 밖으로 나갈 수 있게 사설 아이피를 쓰고 있는데 공인 아이피로 바꿔야지 남도 알 수 있다. 이걸 바꿔주는 것을 나트라고 한다. 내부에서만 쓰는 이름을 외부에서도 알 수 있도록..

라우팅테이블 타겟은 무엇일까? 밖에 있는 어디로 나가야 하는데 타겟이 밖에 있는 어디이다. 컴퓨터는 멍청해서 범위까지 알기 때문에. 가기 전에 많은 라우터들을 거친다. 라우터는 목적지를 가기 위해 거쳐거쳐 다른 목적지로 가는. 1번 정거장. 2번 정거장. 3번 정거장.. 각 각의 정거장마다 물어물어 간다. 이것이 라우터이다. 이 라우터가 있는 대역이 타겟이다. 어느 쪽으로 가라 라고 말해주는 것. 최종 목적지로 가기 위해 거쳐가는 것을 타겟 바깥으로 가는 가장 가까운 문. IGW, NAT GW

인터넷 게이트웨이를 직접 붙여버리면 밖에서도 들어올 수 있다. 그러나 인터넷 게이트웨이까지는 갈 주는 알아야 한다. 이렇게 인터넷 게이트웨이를 가도록 도와주는 애가 NAT 게이트웨이이다. NAT 게이트웨이를 붙여서 라우터를 거쳐서 NAT Gateway  가고 인터넷 게이트웨이로 가고.,

라우팅 테이블은 라우터가 가지고 있다. 그러나 직접 라우터를 설정하지는 않는다. AWS가 설정하는 것이고.

인터넷 게이트웨이는 VPC에 붙어 있다.

### Bastion Host (NAT Instance)

- 

로그인 관련된 컨테이너만 묶은 것을 pod. → login-pod

이 pod가 여섯 개 떠 있다

로드밸런서는 트래픽에 따라 어디로 보낼 지 배분해주는 애를 말한다. 로드밸런서를 만들어서 외부에서 접근 가능하게 해주는게 서비스이다. 노드 그룹의 노드는 워커노드라고도 한다. node group은 하나의 컴퓨터라고 생갓하면 된다. 각각 pod가 있는데 얘는 하나의 응용 어플리케이션 같은 애이다. 이것은 deployment 에서 정한다. 얼만큼의 자원을 사용할 지, 어떤 방시긍로 배포할 지. deployment의 pod는 노드에 배분이 된 것이다. 외부에서 클라이언트 접근을 해야 하는데 서비스를 통해 외부로 노출이 가능하다. 이걸 해주는 게 서비스의 로드밸런서이다.

## 2주차

### Kubernetes란?

- 컨테이너 오케스트레이션 툴
- 컨테이너를 쉽고 빠르게 배포/확장하고 관리를 자동화해주는 오픈소스 플랫폼 = 컨테이너 관리 툴
- Docker가 컨테이너 기반의 가상화를 실현한 플랫폼이라면 Docker Container를 관리하는 것이 Kubernetes

### 등장 배경

- 기존: 어플리케이션을 배포할 때, web, was, java jar 파일, war 파일 등을 매번 똑같이 빌드하고 설치해야 하는 어려움이 있다. 배포 과정을 줄일 수는 없을까?
- Docker: DockerFile에 작은 os, 실행 파일 등을 말아서 도커 이미지를 생성한 후 컨테이너를 실행시키면 같은 작업을 반복하지 않아도 된다. 이렇게 어플리케이션 배포를 쉽게 해주는 게 컨테이너이다. 컨테이너 기술을 이용할 수 있게 해주는 플랫폼을 Docker라고 한다. 컨테이너가 배포 과정을 줄여줬지만 이런 컨테이너를 백개, 천개 관리한다면 너무 어렵고 귀찮을 것이다.
- K8S(=Kubernetes): 컨테이너들을 관리해주는 게 쿠버네티스이다. 블루그린 배포, 카나리 배포 등을 실현할 수 있도록 Deployment, Daemonset과 같은 다양한 배포 방식을 지원하고 Auto Scaling을 지원한다.

### 쿠버네티스 클러스터 아키텍처

![image](https://user-images.githubusercontent.com/50407047/113287451-8ee0bc80-9328-11eb-8569-742c4cfa8ee9.png)

1. 여러 개의 서버가 하나의 클러스터로 연결

2. 쿠버네티스 마스터 = 컨트롤 플레인이 실행됨. 클러스터의 두뇌. 

   컨테이너 스케줄링, 서비스 관리, API 요청 수행 (파드, 리소스 컨트롤러, 로드밸런서 관리)

3. 쿠버네티스 워커노드 = 사용자의 워크로드 실행

   마스터의 관리 아래 pod 같은 리소스가 생성되는 노드

### 관리형  Kubernetes VS 자체 호스팅

- Kubernetes를 자체적으로 구축 가능 (= 자체 호스팅)

  위의 아키텍처를 구축하고 지속적으로 관리 필요. (쿠버네티스는 생각보다 업데이트가 빠르다..ㅠㅠ ) 설치도 어렵다.

- 따라서 **관리형 쿠버네티스 추천 => AWS의 EKS, Google의 GKE, Azure의 AKS**

  기업에서 고가용성이 보장된 쿠버네티스 클러스터 제공 (위의 아키텍처)



### Kubernetes Object

Nginx Pod를 띄우고 Load Balancer type으로 서버를 배포하라는 게 무슨 뜻일까?

1. 쿠버네티스는 상태를 관리하기 위한 대상을 오브젝트로 정의
2. Pod: 쿠버네티스의 가장 작은 배포 단위. 컨테이너의 모임. 하나 이상의 컨테이너로 구성.
3. Deployment: 애플리케이션 배포의 기본 단위가 되는 리소스
4. Service: Pod 를 외부에 노출시켜주는 로드밸런서
5. 위의 오브젝트들은 yaml 파일로 정의하여 kubectl 명령어로 반영한다.

![image](https://user-images.githubusercontent.com/50407047/113287291-58a33d00-9328-11eb-88a2-1cd85ec041ed.png)

- Node(=WorkerNode)는 EKS의 NodeGroup(하나의 컴퓨터). 
- 컨테이너(web application 등)를 담은 Pod는 Deployment에 의해 관리된다.
- Deployment에서 몇 개의 파드가 얼마만큼의 자원을 사용할 지, 어떤 방식으로 배포할 지 정의한다.
- Pod는 각각의 WorkerNode 에 배포되고, 서비스를 통해 외부에 노출된다. (사람들이 인터넷을 통해 접근할 수 있게 외부로 노출)

### Kubernetes Object

Nginx 서비스를 배포하려면?

1.  **Deployment를 정의**하여 Nginx 컨테이너를 담은 pod를 띄운다.
2. Pod를 LoadBalancer  Type의 **Service를 통해 배포**한다.
3. 자동 생성된 ELB를 통해 Nginx가 배포된 것을 확인한다.

### EKS 환경구성

- Bastion에 kubectl 설치

  Bastion을 kubectl 명령어를 수행하는 workspace로 사용

> Bastion은 중세시대에 성 외곽을 보호하기 위해 돌출된 부분을 뜻한다. 즉 배스천에서는 적을 가장 효과적으로 방어할 수 있다. 컴퓨터 네트워크에서도 적을 방어할 수 잇는 부분이 필요한데, 이 역할을 배스천 호스트가 한다.
>
> 배스천 호스트는 접근 제어 기능과 더불어 게이트웨이로서 가상 서버(Proxy Server)의 설치, 인증, 로그 등을 담당한다. 특히 내부와 외부 사이에서 일종의 게이트 역할을 수행한다. 그만큼 위험에 노출되는 경우가 많기 때문에, 배스천 호스트는 네트워크 보안상 가장 중요한 방화벽 호스트이다. 내부 네트워크 전체의 보안을 담당하기 때문에 관리자의 감시 및 정기적인 점검이 뒷받침 되어야 한다. 
>
> https://m.blog.naver.com/PostView.nhn?blogId=pentamkt&logNo=221034903499&proxyReferer=https:%2F%2Fwww.google.com%2F

##  3주차 세션



쿠버네티스

- 컨테이너 오케스트레이션 툴
- 컨테이너를 쉽고 빠르게 배포, 확장하고 관리를 자동화



쿠버네티스 마스터(EKS clustr): AWS에서 자동으로 제공

쿠버네티스 마스터를 직접 관리하는 것은 어렵다. 고가용성의 쿠버네티스를 제공하고 있다. 기업에서 알아서 생성해주고, 업데이트도 해준다. 운영 어플리케이션이 뜨는 곳은 실제로 EKS Node group worker node 이고 여기만 관리하면 된다. 



N/A 사용





kubectl get pod -n ~~ : 여기서 n은 namespace.

논리적으로 upper node안에서 생성된 자원을 분리한다.

default 시스템에는 nginx, 키바나 등등 , kube-system은 쿠버네티스 시스템 자체에서 뜬다. 여기에 fluentd도 마찬가지이다.



KMS: AWS에서 제공하는 암호화 서비스 

람다 함수명을 적으면 그 함수로만 복호화를 할 수 잇다.

 암호화를 할 때는 kms키와 람다함수 이름이 들어간다. 



## 